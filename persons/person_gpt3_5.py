from __future__ import annotations
import warnings

import os
import openai
from typing import Dict, List, Tuple, Any

from persons.person import Person
from session_rooms.session_room import System

# protect cyclic imports caused from typing
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from session_rooms.ChatEntry import ChatEntry



class Person3_5(Person):
    PERSON_TYPE = "person_gpt3_5"
    MODEL_NAME = "gpt-3.5-turbo"

    def __init__(self, background_story: str, name: str, *args, **kwargs):
        super().__init__(background_story, name)
        # Set up your OpenAI API credentials
        openai.api_key = os.environ.get("OPENAI_API_KEY")
        openai.organization = os.environ.get("OPENAI_ORG_ID")
        self.model_name = Person3_5.MODEL_NAME
        warnings.warn("This API has been deprecated by OpenAI")

    def generate_answer(self, experiment_scenario: str, chat_list: List[ChatEntry]):
        generated_prompt: List[Dict[str, str]] = self.create_prompt(experiment_scenario, chat_list)
        full_response = openai.ChatCompletion.create(
            model=self.model_name,  # Specify the chat model
            messages=generated_prompt,  # List of messages representing conversation history
            max_tokens=50,  # Limit the response length to 100 tokens
            n=1,  # Generate a single response
            temperature=0.6,  # Control the randomness of the output
        )
        # Retrieve the generated response
        output_text: str = full_response.choices[0].message['content']
        parsed_answer = output_text
        return ChatEntry(entity=self, prompt=generated_prompt, answer=parsed_answer)

    #TODO: Choose the best prompt and prompt structure (should it all be in system?)
    def create_prompt(self, experiment_scenario: str,
                      chat_list: List[ChatEntry]) -> List[Dict[str, str]]:
        """ 
        Creates a prompt with the past conversation in the format expected by OpenAI Chat API.
        The returned conversation is a list of entries, which follows the format described at
        https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide.

        In particular, the "role" property has 3 values, which we use as follows:
            - "system": Only used in the first / last entries to set up the person instance identity.
            - "assistant": Used for messages generated by the person instance.
            - "user": Used for messages generated by other persons. Each entry can consist of 
              messages from multiple persons, by concatenating the format "{name}: {content}\n".
        """
        
        name_message = {"role": "system", "content": f"Your name is {self.name}."}
        scenario_message = {"role": "system", "content": f"The scenario is the following:"
                                                         f" {experiment_scenario}"}
        system_message = {"role": "system", "content": f"This is your background story:"
                                                       f" {self.background_story}"}
        conversation = [name_message, scenario_message, system_message]

        other_users_prompt = ""
        for chat_entry in chat_list:
            if isinstance(chat_entry.entity, System): # System message
                if other_users_prompt:
                    conversation.append({"role": "user", "content": other_users_prompt})
                conversation.append({"role": "system", "content": chat_entry.answer})
                other_users_prompt = ""
            elif chat_entry.entity is self:  # My previous message
                if other_users_prompt:
                    conversation.append({"role": "user", "content": other_users_prompt})
                conversation.append({"role": "assistant", "content": chat_entry.answer})
                other_users_prompt = ""
            else: # Other user message
                if other_users_prompt:
                    other_users_prompt += "\n"
                other_users_prompt += f"{chat_entry.entity.name}: {chat_entry.answer}"

        if other_users_prompt:
            conversation.append({"role": "user", "content": other_users_prompt})

        return conversation
